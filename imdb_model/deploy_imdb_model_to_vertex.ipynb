{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88d03db6-579b-41a4-9cce-a5de6cdae74c",
   "metadata": {},
   "source": [
    "## Before you begin\n",
    "\n",
    "### Set up your Google Cloud project\n",
    "\n",
    "**The following steps are required, regardless of your notebook environment (Vertex AI Workbench, Colab, or local).**\n",
    "\n",
    "1. **Select or create a Google Cloud project**  \n",
    "   https://console.cloud.google.com/cloud-resource-manager  \n",
    "   ↳ Your Google Cloud account includes $300 free credit for new users.\n",
    "\n",
    "2. **Make sure that billing is enabled for your project**  \n",
    "   https://cloud.google.com/billing/docs/how-to/modify-project  \n",
    "\n",
    "3. **Enable the required Google Cloud APIs**\n",
    "\n",
    "This tutorial uses a **custom prediction container**, **Artifact Registry**, **Cloud Build**, and **Vertex AI**, so you must enable all the following:\n",
    "\n",
    "| API | Purpose |\n",
    "|-----|---------|\n",
    "| `aiplatform.googleapis.com` | Vertex AI (model registry, endpoints, predictions) |\n",
    "| `artifactregistry.googleapis.com` | Stores your custom Docker images |\n",
    "| `cloudbuild.googleapis.com` | Builds the container image from your Dockerfile |\n",
    "| `storage.googleapis.com` | Allows reading/writing to Cloud Storage buckets |\n",
    "| `compute.googleapis.com` | Required for Endpoint deployment VMs |\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "# Deploy IMDB Sentiment Model to Vertex AI Endpoint\n",
    "\n",
    "Hands-on workshop notebook for deploying a BERT-based IMDB sentiment model as a real-time endpoint on Vertex AI, using a custom FastAPI container.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Environment and prerequisites\n",
    "\n",
    "**Why this section?**  \n",
    "Vertex AI calls your model through a container. That container and your notebook need the right Python libraries and SDKs.\n",
    "\n",
    "### 1.1 Install Python dependencies\n",
    "\n",
    "```python\n",
    "# Core libraries:\n",
    "# - google-cloud-aiplatform: Vertex AI SDK for Python\n",
    "# - fastapi, uvicorn: web server inside the container\n",
    "# - transformers, torch: Hugging Face BERT model and backend\n",
    "# - pydantic: request validation for FastAPI\n",
    "\n",
    "!pip install -q \"google-cloud-aiplatform>=1.49.0\" fastapi uvicorn transformers torch pydantic\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96159bdc-59bf-4a6a-83c5-a0257cd3ced9",
   "metadata": {},
   "source": [
    "### Enviroment and prerequirsites\n",
    "-Configure project variables\n",
    "- Why this section?\n",
    "- We centralise configuration so you only edit project/region names in one place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7494d414-1f10-439b-9849-c6b9a09d50f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T09:59:22.058449Z",
     "iopub.status.busy": "2025-11-27T09:59:22.058043Z",
     "iopub.status.idle": "2025-11-27T09:59:25.422713Z",
     "shell.execute_reply": "2025-11-27T09:59:25.421075Z",
     "shell.execute_reply.started": "2025-11-27T09:59:22.058414Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# If needed, install extra libraries (Workbench usually has aiplatform preinstalled)\n",
    "!pip install -q \"google-cloud-aiplatform>=1.49.0\" fastapi uvicorn transformers torch pydantic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd864702-3625-4f1f-ad01-125ae2d1a3d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T09:59:46.436335Z",
     "iopub.status.busy": "2025-11-27T09:59:46.435870Z",
     "iopub.status.idle": "2025-11-27T09:59:47.644591Z",
     "shell.execute_reply": "2025-11-27T09:59:47.642813Z",
     "shell.execute_reply.started": "2025-11-27T09:59:46.436294Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFORMATION: Project 'vast-collective-478617-j1' has no 'environment' tag set. Use either 'Production', 'Development', 'Test', or 'Staging'. Add an 'environment' tag using `gcloud resource-manager tags bindings create`.\n",
      "[compute]\n",
      "region = us-central1\n",
      "[core]\n",
      "account = 60487384516-compute@developer.gserviceaccount.com\n",
      "disable_usage_reporting = True\n",
      "project = vast-collective-478617-j1\n",
      "universe_domain = googleapis.com\n",
      "[dataproc]\n",
      "region = us-central1\n",
      "\n",
      "Your active configuration is: [default]\n"
     ]
    }
   ],
   "source": [
    "!gcloud config list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16e1ab0-77e8-4905-a092-14eeff4b75aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05f11d07-348f-4578-bc00-87d7b2524441",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T10:01:41.521380Z",
     "iopub.status.busy": "2025-11-27T10:01:41.520771Z",
     "iopub.status.idle": "2025-11-27T10:01:46.506515Z",
     "shell.execute_reply": "2025-11-27T10:01:46.504788Z",
     "shell.execute_reply.started": "2025-11-27T10:01:41.521332Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from google.cloud import aiplatform\n",
    "\n",
    "# ----- REQUIRED: EDIT THESE VALUES -----\n",
    "PROJECT_ID = \"vast-collective-478617-j1\"\n",
    "REGION = \"us-central1\"  # or your chosen region\n",
    "ARTIFACT_REPO = \"vertex-mlops-repo\"  # Artifact Registry repo name (will be created if it does not exist)\n",
    "IMAGE_NAME = \"imdb-sentiment-bert\"\n",
    "MODEL_DISPLAY_NAME = \"imdb-bert-sentiment\"\n",
    "ENDPOINT_DISPLAY_NAME = \"imdb-bert-sentiment-endpoint\"\n",
    "LOCATION = REGION  # same as REGION\n",
    "# --------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c156f60e-7dcd-4b5d-b082-7c747ddd92e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T10:01:59.784777Z",
     "iopub.status.busy": "2025-11-27T10:01:59.784173Z",
     "iopub.status.idle": "2025-11-27T10:02:01.076726Z",
     "shell.execute_reply": "2025-11-27T10:02:01.075242Z",
     "shell.execute_reply.started": "2025-11-27T10:01:59.784734Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFORMATION: Project 'vast-collective-478617-j1' has no 'environment' tag set. Use either 'Production', 'Development', 'Test', or 'Staging'. Add an 'environment' tag using `gcloud resource-manager tags bindings create`.\n",
      "Updated property [core/project].\n"
     ]
    }
   ],
   "source": [
    "# Set the project for gcloud in this Workbench VM\n",
    "!gcloud config set project {PROJECT_ID}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04d4bd92-53a9-4770-8bcb-b9b38482594e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T10:02:17.857345Z",
     "iopub.status.busy": "2025-11-27T10:02:17.856898Z",
     "iopub.status.idle": "2025-11-27T10:02:21.809363Z",
     "shell.execute_reply": "2025-11-27T10:02:21.807726Z",
     "shell.execute_reply.started": "2025-11-27T10:02:17.857305Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operation \"operations/acat.p2-60487384516-93a62d7e-63cd-4303-9801-5ae2b31e724c\" finished successfully.\n"
     ]
    }
   ],
   "source": [
    "# Enable required APIs (run once per project)\n",
    "!gcloud services enable \\\n",
    "    aiplatform.googleapis.com \\\n",
    "    artifactregistry.googleapis.com \\\n",
    "    cloudbuild.googleapis.com\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247cb5a5-aaa7-4f7b-96dc-c32635094cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Create an Artifact Registry repository (for container images)\n",
    "\n",
    "# If the repo already exists, this will just error harmlessly; you can ignore \"already exists\" messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74c86557-1249-4474-a674-ff437b734899",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T10:03:19.701542Z",
     "iopub.status.busy": "2025-11-27T10:03:19.701050Z",
     "iopub.status.idle": "2025-11-27T10:03:22.887745Z",
     "shell.execute_reply": "2025-11-27T10:03:22.886291Z",
     "shell.execute_reply.started": "2025-11-27T10:03:19.701479Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create request issued for: [vertex-mlops-repo]\n",
      "Waiting for operation [projects/vast-collective-478617-j1/locations/us-central1\n",
      "/operations/b60e3de3-a109-4f98-b1ba-415eed959f4e] to complete...done.          \n",
      "Created repository [vertex-mlops-repo].\n"
     ]
    }
   ],
   "source": [
    "!gcloud artifacts repositories create {ARTIFACT_REPO} \\\n",
    "    --repository-format=docker \\\n",
    "    --location={REGION} \\\n",
    "    --description=\"Repo for Vertex AI custom containers\" || echo \"Repo may already exist\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66afe15f-8c39-4a38-8240-995e8cdc8d06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T10:03:47.373105Z",
     "iopub.status.busy": "2025-11-27T10:03:47.372587Z",
     "iopub.status.idle": "2025-11-27T10:03:47.385137Z",
     "shell.execute_reply": "2025-11-27T10:03:47.383727Z",
     "shell.execute_reply.started": "2025-11-27T10:03:47.372992Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'us-central1-docker.pkg.dev/vast-collective-478617-j1/vertex-mlops-repo/imdb-sentiment-bert:v1'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMAGE_URI = f\"{REGION}-docker.pkg.dev/{PROJECT_ID}/{ARTIFACT_REPO}/{IMAGE_NAME}:v1\"\n",
    "IMAGE_URI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa354e7-bb33-49d5-83bc-3366345fd634",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2086a4e-8ade-4144-ad90-4194d0005881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Build the serving app (FastAPI + Hugging Face model)\n",
    "\n",
    "# We will create a small app that:\n",
    "\n",
    "# Loads philipobiorah/bert-imdb-model and tokenizer.\n",
    "\n",
    "# Exposes /ping for health checks.\n",
    "\n",
    "# Exposes /predict to accept text and return sentiment + confidence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72ba5826-5fed-4943-88af-1845906e43b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T10:07:03.530918Z",
     "iopub.status.busy": "2025-11-27T10:07:03.530226Z",
     "iopub.status.idle": "2025-11-27T10:07:03.804554Z",
     "shell.execute_reply": "2025-11-27T10:07:03.802733Z",
     "shell.execute_reply.started": "2025-11-27T10:07:03.530834Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/v3_2/imdb_serving_app\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "!rm -rf imdb_serving_app\n",
    "!mkdir -p imdb_serving_app\n",
    "%cd imdb_serving_app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80e74303-d982-46d2-8237-fde37d1fd90c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T10:08:06.032622Z",
     "iopub.status.busy": "2025-11-27T10:08:06.031489Z",
     "iopub.status.idle": "2025-11-27T10:08:06.045434Z",
     "shell.execute_reply": "2025-11-27T10:08:06.043514Z",
     "shell.execute_reply.started": "2025-11-27T10:08:06.032571Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing main.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile main.py\n",
    "from fastapi import FastAPI\n",
    "from pydantic import BaseModel\n",
    "from typing import List\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "# Load tokenizer and model at startup\n",
    "MODEL_NAME = \"philipobiorah/bert-imdb-model\"\n",
    "BASE_TOKENIZER_NAME = \"bert-base-uncased\"\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(BASE_TOKENIZER_NAME)\n",
    "model = BertForSequenceClassification.from_pretrained(MODEL_NAME)\n",
    "model.eval()  # set to evaluation mode\n",
    "\n",
    "class Instance(BaseModel):\n",
    "    text: str\n",
    "\n",
    "class PredictRequest(BaseModel):\n",
    "    instances: List[Instance]\n",
    "\n",
    "@app.get(\"/ping\")\n",
    "def health_check():\n",
    "    return {\"status\": \"ok\"}\n",
    "\n",
    "@app.post(\"/predict\")\n",
    "def predict(request: PredictRequest):\n",
    "    texts = [inst.text for inst in request.instances]\n",
    "\n",
    "    # Tokenize batch\n",
    "    inputs = tokenizer(\n",
    "        texts,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        max_length=512\n",
    "    )\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "\n",
    "    probs = torch.nn.functional.softmax(logits, dim=1)\n",
    "    predictions = []\n",
    "\n",
    "    for i, text in enumerate(texts):\n",
    "        prob = probs[i]\n",
    "        sentiment_idx = prob.argmax().item()\n",
    "        confidence = prob[sentiment_idx].item() * 100.0\n",
    "        sentiment_label = \"Positive\" if sentiment_idx == 1 else \"Negative\"\n",
    "\n",
    "        predictions.append({\n",
    "            \"text\": text,\n",
    "            \"sentiment\": sentiment_label,\n",
    "            \"confidence\": round(confidence, 2)\n",
    "        })\n",
    "\n",
    "    # Vertex AI expects {\"predictions\": [...]}\n",
    "    return {\"predictions\": predictions}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d6a73f0-00d6-4d52-b45b-cd06fc7bb651",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T10:08:36.937285Z",
     "iopub.status.busy": "2025-11-27T10:08:36.936129Z",
     "iopub.status.idle": "2025-11-27T10:08:36.944335Z",
     "shell.execute_reply": "2025-11-27T10:08:36.942971Z",
     "shell.execute_reply.started": "2025-11-27T10:08:36.937230Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile requirements.txt\n",
    "fastapi\n",
    "uvicorn[standard]\n",
    "torch\n",
    "transformers\n",
    "pydantic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d846dc9-c0d2-49a2-a943-ca1497123be2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T10:09:33.464133Z",
     "iopub.status.busy": "2025-11-27T10:09:33.463623Z",
     "iopub.status.idle": "2025-11-27T10:09:33.473424Z",
     "shell.execute_reply": "2025-11-27T10:09:33.472000Z",
     "shell.execute_reply.started": "2025-11-27T10:09:33.464082Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing Dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%writefile Dockerfile\n",
    "FROM python:3.10-slim\n",
    "\n",
    "# Prevents Python from writing pyc files and buffering stdout/stderr\n",
    "ENV PYTHONDONTWRITEBYTECODE=1\n",
    "ENV PYTHONUNBUFFERED=1\n",
    "\n",
    "# Install system dependencies\n",
    "RUN apt-get update && apt-get install -y --no-install-recommends \\\n",
    "    git \\\n",
    "    && rm -rf /var/lib/apt/lists/*\n",
    "\n",
    "# Workdir\n",
    "WORKDIR /app\n",
    "\n",
    "# Copy requirements and install\n",
    "COPY requirements.txt .\n",
    "RUN pip install --no-cache-dir -r requirements.txt\n",
    "\n",
    "# Copy app code\n",
    "COPY main.py .\n",
    "\n",
    "# Expose port\n",
    "EXPOSE 8080\n",
    "\n",
    "# Start FastAPI app\n",
    "CMD [\"uvicorn\", \"main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8080\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da82dd4-e1fc-48b4-94eb-628bffa90b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Build and push the container image using Cloud Build\n",
    "\n",
    "# We build the image in the current directory (which contains Dockerfile, main.py, requirements.txt) and push it to Artifact Registry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9aec7183-36ff-4d81-822f-f42a060481cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T10:10:16.146959Z",
     "iopub.status.busy": "2025-11-27T10:10:16.146479Z",
     "iopub.status.idle": "2025-11-27T10:18:13.502532Z",
     "shell.execute_reply": "2025-11-27T10:18:13.500856Z",
     "shell.execute_reply.started": "2025-11-27T10:10:16.146914Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating temporary archive of 3 file(s) totalling 2.1 KiB before compression.\n",
      "Uploading tarball of [.] to [gs://vast-collective-478617-j1_cloudbuild/source/1764238217.206755-305469b3485b4337b2e6485866cc65ce.tgz]\n",
      "Created [https://cloudbuild.googleapis.com/v1/projects/vast-collective-478617-j1/locations/global/builds/627a9a13-a235-45a8-a346-4ca77253d26e].\n",
      "Logs are available at [ https://console.cloud.google.com/cloud-build/builds/627a9a13-a235-45a8-a346-4ca77253d26e?project=60487384516 ].\n",
      "Waiting for build to complete. Polling interval: 1 second(s).\n",
      "----------------------------- REMOTE BUILD OUTPUT ------------------------------\n",
      "starting build \"627a9a13-a235-45a8-a346-4ca77253d26e\"\n",
      "\n",
      "FETCHSOURCE\n",
      "Fetching storage object: gs://vast-collective-478617-j1_cloudbuild/source/1764238217.206755-305469b3485b4337b2e6485866cc65ce.tgz#1764238217459660\n",
      "Copying gs://vast-collective-478617-j1_cloudbuild/source/1764238217.206755-305469b3485b4337b2e6485866cc65ce.tgz#1764238217459660...\n",
      "/ [1 files][  1.3 KiB/  1.3 KiB]                                                \n",
      "Operation completed over 1 objects/1.3 KiB.\n",
      "BUILD\n",
      "Already have image (with digest): gcr.io/cloud-builders/gcb-internal\n",
      "Sending build context to Docker daemon  6.144kB\n",
      "Step 1/10 : FROM python:3.10-slim\n",
      "3.10-slim: Pulling from library/python\n",
      "0e4bc2bd6656: Pulling fs layer\n",
      "9793cbb1e51a: Pulling fs layer\n",
      "683c3659b1e9: Pulling fs layer\n",
      "f86ba98c4d0f: Pulling fs layer\n",
      "f86ba98c4d0f: Verifying Checksum\n",
      "f86ba98c4d0f: Download complete\n",
      "9793cbb1e51a: Verifying Checksum\n",
      "9793cbb1e51a: Download complete\n",
      "683c3659b1e9: Verifying Checksum\n",
      "683c3659b1e9: Download complete\n",
      "0e4bc2bd6656: Verifying Checksum\n",
      "0e4bc2bd6656: Download complete\n",
      "0e4bc2bd6656: Pull complete\n",
      "9793cbb1e51a: Pull complete\n",
      "683c3659b1e9: Pull complete\n",
      "f86ba98c4d0f: Pull complete\n",
      "Digest: sha256:c299e10e0070171113f9a1f109dd05e7e634fa94589b056e0e87bb22b2b382a2\n",
      "Status: Downloaded newer image for python:3.10-slim\n",
      " ---> 6f924957e3d2\n",
      "Step 2/10 : ENV PYTHONDONTWRITEBYTECODE=1\n",
      " ---> Running in d373793207d4\n",
      "Removing intermediate container d373793207d4\n",
      " ---> 787b3eb0318a\n",
      "Step 3/10 : ENV PYTHONUNBUFFERED=1\n",
      " ---> Running in 8f726114f926\n",
      "Removing intermediate container 8f726114f926\n",
      " ---> bb37457387fb\n",
      "Step 4/10 : RUN apt-get update && apt-get install -y --no-install-recommends     git     && rm -rf /var/lib/apt/lists/*\n",
      " ---> Running in 65bd519c294d\n",
      "Hit:1 http://deb.debian.org/debian trixie InRelease\n",
      "Get:2 http://deb.debian.org/debian trixie-updates InRelease [47.3 kB]\n",
      "Get:3 http://deb.debian.org/debian-security trixie-security InRelease [43.4 kB]\n",
      "Get:4 http://deb.debian.org/debian trixie/main amd64 Packages [9670 kB]\n",
      "Get:5 http://deb.debian.org/debian trixie-updates/main amd64 Packages [5412 B]\n",
      "Get:6 http://deb.debian.org/debian-security trixie-security/main amd64 Packages [73.1 kB]\n",
      "Fetched 9839 kB in 1s (11.1 MB/s)\n",
      "Reading package lists...\n",
      "Reading package lists...\n",
      "Building dependency tree...\n",
      "Reading state information...\n",
      "The following additional packages will be installed:\n",
      "  git-man libbrotli1 libcom-err2 libcurl3t64-gnutls liberror-perl libexpat1\n",
      "  libgdbm-compat4t64 libgnutls30t64 libgssapi-krb5-2 libidn2-0 libk5crypto3\n",
      "  libkeyutils1 libkrb5-3 libkrb5support0 libldap2 libnghttp2-14 libnghttp3-9\n",
      "  libngtcp2-16 libngtcp2-crypto-gnutls8 libp11-kit0 libperl5.40 libpsl5t64\n",
      "  librtmp1 libsasl2-2 libsasl2-modules-db libssh2-1t64 libtasn1-6\n",
      "  libunistring5 perl perl-modules-5.40\n",
      "Suggested packages:\n",
      "  gettext-base git-doc git-email git-gui gitk gitweb git-cvs git-mediawiki\n",
      "  git-svn gnutls-bin krb5-doc krb5-user sensible-utils perl-doc\n",
      "  libterm-readline-gnu-perl | libterm-readline-perl-perl make\n",
      "  libtap-harness-archive-perl\n",
      "Recommended packages:\n",
      "  patch less ssh-client krb5-locales libldap-common publicsuffix\n",
      "  libsasl2-modules\n",
      "The following NEW packages will be installed:\n",
      "  git git-man libbrotli1 libcom-err2 libcurl3t64-gnutls liberror-perl\n",
      "  libexpat1 libgdbm-compat4t64 libgnutls30t64 libgssapi-krb5-2 libidn2-0\n",
      "  libk5crypto3 libkeyutils1 libkrb5-3 libkrb5support0 libldap2 libnghttp2-14\n",
      "  libnghttp3-9 libngtcp2-16 libngtcp2-crypto-gnutls8 libp11-kit0 libperl5.40\n",
      "  libpsl5t64 librtmp1 libsasl2-2 libsasl2-modules-db libssh2-1t64 libtasn1-6\n",
      "  libunistring5 perl perl-modules-5.40\n",
      "0 upgraded, 31 newly installed, 0 to remove and 0 not upgraded.\n",
      "Need to get 23.6 MB of archives.\n",
      "After this operation, 119 MB of additional disk space will be used.\n",
      "Get:1 http://deb.debian.org/debian trixie/main amd64 libexpat1 amd64 2.7.1-2 [108 kB]\n",
      "Get:2 http://deb.debian.org/debian trixie/main amd64 perl-modules-5.40 all 5.40.1-6 [3019 kB]\n",
      "Get:3 http://deb.debian.org/debian trixie/main amd64 libgdbm-compat4t64 amd64 1.24-2 [50.3 kB]\n",
      "Get:4 http://deb.debian.org/debian trixie/main amd64 libperl5.40 amd64 5.40.1-6 [4341 kB]\n",
      "Get:5 http://deb.debian.org/debian trixie/main amd64 perl amd64 5.40.1-6 [267 kB]\n",
      "Get:6 http://deb.debian.org/debian trixie/main amd64 libbrotli1 amd64 1.1.0-2+b7 [307 kB]\n",
      "Get:7 http://deb.debian.org/debian trixie/main amd64 libunistring5 amd64 1.3-2 [477 kB]\n",
      "Get:8 http://deb.debian.org/debian trixie/main amd64 libidn2-0 amd64 2.3.8-2 [109 kB]\n",
      "Get:9 http://deb.debian.org/debian trixie/main amd64 libp11-kit0 amd64 0.25.5-3 [425 kB]\n",
      "Get:10 http://deb.debian.org/debian trixie/main amd64 libtasn1-6 amd64 4.20.0-2 [49.9 kB]\n",
      "Get:11 http://deb.debian.org/debian trixie/main amd64 libgnutls30t64 amd64 3.8.9-3 [1465 kB]\n",
      "Get:12 http://deb.debian.org/debian trixie/main amd64 libkrb5support0 amd64 1.21.3-5 [33.0 kB]\n",
      "Get:13 http://deb.debian.org/debian trixie/main amd64 libcom-err2 amd64 1.47.2-3+b3 [25.0 kB]\n",
      "Get:14 http://deb.debian.org/debian trixie/main amd64 libk5crypto3 amd64 1.21.3-5 [81.5 kB]\n",
      "Get:15 http://deb.debian.org/debian trixie/main amd64 libkeyutils1 amd64 1.6.3-6 [9456 B]\n",
      "Get:16 http://deb.debian.org/debian trixie/main amd64 libkrb5-3 amd64 1.21.3-5 [326 kB]\n",
      "Get:17 http://deb.debian.org/debian trixie/main amd64 libgssapi-krb5-2 amd64 1.21.3-5 [138 kB]\n",
      "Get:18 http://deb.debian.org/debian trixie/main amd64 libsasl2-modules-db amd64 2.1.28+dfsg1-9 [19.8 kB]\n",
      "Get:19 http://deb.debian.org/debian trixie/main amd64 libsasl2-2 amd64 2.1.28+dfsg1-9 [57.5 kB]\n",
      "Get:20 http://deb.debian.org/debian trixie/main amd64 libldap2 amd64 2.6.10+dfsg-1 [194 kB]\n",
      "Get:21 http://deb.debian.org/debian trixie/main amd64 libnghttp2-14 amd64 1.64.0-1.1 [76.0 kB]\n",
      "Get:22 http://deb.debian.org/debian trixie/main amd64 libnghttp3-9 amd64 1.8.0-1 [67.7 kB]\n",
      "Get:23 http://deb.debian.org/debian trixie/main amd64 libngtcp2-16 amd64 1.11.0-1 [131 kB]\n",
      "Get:24 http://deb.debian.org/debian trixie/main amd64 libngtcp2-crypto-gnutls8 amd64 1.11.0-1 [29.3 kB]\n",
      "Get:25 http://deb.debian.org/debian trixie/main amd64 libpsl5t64 amd64 0.21.2-1.1+b1 [57.2 kB]\n",
      "Get:26 http://deb.debian.org/debian trixie/main amd64 librtmp1 amd64 2.4+20151223.gitfa8646d.1-2+b5 [58.8 kB]\n",
      "Get:27 http://deb.debian.org/debian trixie/main amd64 libssh2-1t64 amd64 1.11.1-1 [245 kB]\n",
      "Get:28 http://deb.debian.org/debian trixie/main amd64 libcurl3t64-gnutls amd64 8.14.1-2+deb13u2 [383 kB]\n",
      "Get:29 http://deb.debian.org/debian trixie/main amd64 liberror-perl all 0.17030-1 [26.9 kB]\n",
      "Get:30 http://deb.debian.org/debian trixie/main amd64 git-man all 1:2.47.3-0+deb13u1 [2205 kB]\n",
      "Get:31 http://deb.debian.org/debian trixie/main amd64 git amd64 1:2.47.3-0+deb13u1 [8862 kB]\n",
      "\u001b[91mdebconf: unable to initialize frontend: Dialog\n",
      "debconf: (TERM is not set, so the dialog frontend is not usable.)\n",
      "debconf: falling back to frontend: Readline\n",
      "\u001b[0m\u001b[91mdebconf: unable to initialize frontend: Readline\n",
      "\u001b[0m\u001b[91mdebconf: (Can't locate Term/ReadLine.pm in @INC (you may need to install the Term::ReadLine module) (@INC entries checked: /etc/perl /usr/local/lib/x86_64-linux-gnu/perl/5.40.1 /usr/local/share/perl/5.40.1 /usr/lib/x86_64-linux-gnu/perl5/5.40 /usr/share/perl5 /usr/lib/x86_64-linux-gnu/perl-base /usr/lib/x86_64-linux-gnu/perl/5.40 /usr/share/perl/5.40 /usr/local/lib/site_perl) at /usr/share/perl5/Debconf/FrontEnd/Readline.pm line 8, <STDIN> line 31.)\n",
      "\u001b[0m\u001b[91mdebconf: falling back to frontend: Teletype\n",
      "\u001b[0m\u001b[91mdebconf: unable to initialize frontend: Teletype\n",
      "debconf: (This frontend requires a controlling tty.)\n",
      "debconf: falling back to frontend: Noninteractive\n",
      "\u001b[0mFetched 23.6 MB in 0s (86.5 MB/s)\n",
      "Selecting previously unselected package libexpat1:amd64.\n",
      "(Reading database ... 5644 files and directories currently installed.)\n",
      "Preparing to unpack .../00-libexpat1_2.7.1-2_amd64.deb ...\n",
      "Unpacking libexpat1:amd64 (2.7.1-2) ...\n",
      "Selecting previously unselected package perl-modules-5.40.\n",
      "Preparing to unpack .../01-perl-modules-5.40_5.40.1-6_all.deb ...\n",
      "Unpacking perl-modules-5.40 (5.40.1-6) ...\n",
      "Selecting previously unselected package libgdbm-compat4t64:amd64.\n",
      "Preparing to unpack .../02-libgdbm-compat4t64_1.24-2_amd64.deb ...\n",
      "Unpacking libgdbm-compat4t64:amd64 (1.24-2) ...\n",
      "Selecting previously unselected package libperl5.40:amd64.\n",
      "Preparing to unpack .../03-libperl5.40_5.40.1-6_amd64.deb ...\n",
      "Unpacking libperl5.40:amd64 (5.40.1-6) ...\n",
      "Selecting previously unselected package perl.\n",
      "Preparing to unpack .../04-perl_5.40.1-6_amd64.deb ...\n",
      "Unpacking perl (5.40.1-6) ...\n",
      "Selecting previously unselected package libbrotli1:amd64.\n",
      "Preparing to unpack .../05-libbrotli1_1.1.0-2+b7_amd64.deb ...\n",
      "Unpacking libbrotli1:amd64 (1.1.0-2+b7) ...\n",
      "Selecting previously unselected package libunistring5:amd64.\n",
      "Preparing to unpack .../06-libunistring5_1.3-2_amd64.deb ...\n",
      "Unpacking libunistring5:amd64 (1.3-2) ...\n",
      "Selecting previously unselected package libidn2-0:amd64.\n",
      "Preparing to unpack .../07-libidn2-0_2.3.8-2_amd64.deb ...\n",
      "Unpacking libidn2-0:amd64 (2.3.8-2) ...\n",
      "Selecting previously unselected package libp11-kit0:amd64.\n",
      "Preparing to unpack .../08-libp11-kit0_0.25.5-3_amd64.deb ...\n",
      "Unpacking libp11-kit0:amd64 (0.25.5-3) ...\n",
      "Selecting previously unselected package libtasn1-6:amd64.\n",
      "Preparing to unpack .../09-libtasn1-6_4.20.0-2_amd64.deb ...\n",
      "Unpacking libtasn1-6:amd64 (4.20.0-2) ...\n",
      "Selecting previously unselected package libgnutls30t64:amd64.\n",
      "Preparing to unpack .../10-libgnutls30t64_3.8.9-3_amd64.deb ...\n",
      "Unpacking libgnutls30t64:amd64 (3.8.9-3) ...\n",
      "Selecting previously unselected package libkrb5support0:amd64.\n",
      "Preparing to unpack .../11-libkrb5support0_1.21.3-5_amd64.deb ...\n",
      "Unpacking libkrb5support0:amd64 (1.21.3-5) ...\n",
      "Selecting previously unselected package libcom-err2:amd64.\n",
      "Preparing to unpack .../12-libcom-err2_1.47.2-3+b3_amd64.deb ...\n",
      "Unpacking libcom-err2:amd64 (1.47.2-3+b3) ...\n",
      "Selecting previously unselected package libk5crypto3:amd64.\n",
      "Preparing to unpack .../13-libk5crypto3_1.21.3-5_amd64.deb ...\n",
      "Unpacking libk5crypto3:amd64 (1.21.3-5) ...\n",
      "Selecting previously unselected package libkeyutils1:amd64.\n",
      "Preparing to unpack .../14-libkeyutils1_1.6.3-6_amd64.deb ...\n",
      "Unpacking libkeyutils1:amd64 (1.6.3-6) ...\n",
      "Selecting previously unselected package libkrb5-3:amd64.\n",
      "Preparing to unpack .../15-libkrb5-3_1.21.3-5_amd64.deb ...\n",
      "Unpacking libkrb5-3:amd64 (1.21.3-5) ...\n",
      "Selecting previously unselected package libgssapi-krb5-2:amd64.\n",
      "Preparing to unpack .../16-libgssapi-krb5-2_1.21.3-5_amd64.deb ...\n",
      "Unpacking libgssapi-krb5-2:amd64 (1.21.3-5) ...\n",
      "Selecting previously unselected package libsasl2-modules-db:amd64.\n",
      "Preparing to unpack .../17-libsasl2-modules-db_2.1.28+dfsg1-9_amd64.deb ...\n",
      "Unpacking libsasl2-modules-db:amd64 (2.1.28+dfsg1-9) ...\n",
      "Selecting previously unselected package libsasl2-2:amd64.\n",
      "Preparing to unpack .../18-libsasl2-2_2.1.28+dfsg1-9_amd64.deb ...\n",
      "Unpacking libsasl2-2:amd64 (2.1.28+dfsg1-9) ...\n",
      "Selecting previously unselected package libldap2:amd64.\n",
      "Preparing to unpack .../19-libldap2_2.6.10+dfsg-1_amd64.deb ...\n",
      "Unpacking libldap2:amd64 (2.6.10+dfsg-1) ...\n",
      "Selecting previously unselected package libnghttp2-14:amd64.\n",
      "Preparing to unpack .../20-libnghttp2-14_1.64.0-1.1_amd64.deb ...\n",
      "Unpacking libnghttp2-14:amd64 (1.64.0-1.1) ...\n",
      "Selecting previously unselected package libnghttp3-9:amd64.\n",
      "Preparing to unpack .../21-libnghttp3-9_1.8.0-1_amd64.deb ...\n",
      "Unpacking libnghttp3-9:amd64 (1.8.0-1) ...\n",
      "Selecting previously unselected package libngtcp2-16:amd64.\n",
      "Preparing to unpack .../22-libngtcp2-16_1.11.0-1_amd64.deb ...\n",
      "Unpacking libngtcp2-16:amd64 (1.11.0-1) ...\n",
      "Selecting previously unselected package libngtcp2-crypto-gnutls8:amd64.\n",
      "Preparing to unpack .../23-libngtcp2-crypto-gnutls8_1.11.0-1_amd64.deb ...\n",
      "Unpacking libngtcp2-crypto-gnutls8:amd64 (1.11.0-1) ...\n",
      "Selecting previously unselected package libpsl5t64:amd64.\n",
      "Preparing to unpack .../24-libpsl5t64_0.21.2-1.1+b1_amd64.deb ...\n",
      "Unpacking libpsl5t64:amd64 (0.21.2-1.1+b1) ...\n",
      "Selecting previously unselected package librtmp1:amd64.\n",
      "Preparing to unpack .../25-librtmp1_2.4+20151223.gitfa8646d.1-2+b5_amd64.deb ...\n",
      "Unpacking librtmp1:amd64 (2.4+20151223.gitfa8646d.1-2+b5) ...\n",
      "Selecting previously unselected package libssh2-1t64:amd64.\n",
      "Preparing to unpack .../26-libssh2-1t64_1.11.1-1_amd64.deb ...\n",
      "Unpacking libssh2-1t64:amd64 (1.11.1-1) ...\n",
      "Selecting previously unselected package libcurl3t64-gnutls:amd64.\n",
      "Preparing to unpack .../27-libcurl3t64-gnutls_8.14.1-2+deb13u2_amd64.deb ...\n",
      "Unpacking libcurl3t64-gnutls:amd64 (8.14.1-2+deb13u2) ...\n",
      "Selecting previously unselected package liberror-perl.\n",
      "Preparing to unpack .../28-liberror-perl_0.17030-1_all.deb ...\n",
      "Unpacking liberror-perl (0.17030-1) ...\n",
      "Selecting previously unselected package git-man.\n",
      "Preparing to unpack .../29-git-man_1%3a2.47.3-0+deb13u1_all.deb ...\n",
      "Unpacking git-man (1:2.47.3-0+deb13u1) ...\n",
      "Selecting previously unselected package git.\n",
      "Preparing to unpack .../30-git_1%3a2.47.3-0+deb13u1_amd64.deb ...\n",
      "Unpacking git (1:2.47.3-0+deb13u1) ...\n",
      "Setting up libexpat1:amd64 (2.7.1-2) ...\n",
      "Setting up libkeyutils1:amd64 (1.6.3-6) ...\n",
      "Setting up libgdbm-compat4t64:amd64 (1.24-2) ...\n",
      "Setting up libbrotli1:amd64 (1.1.0-2+b7) ...\n",
      "Setting up libnghttp2-14:amd64 (1.64.0-1.1) ...\n",
      "Setting up libcom-err2:amd64 (1.47.2-3+b3) ...\n",
      "Setting up libkrb5support0:amd64 (1.21.3-5) ...\n",
      "Setting up libsasl2-modules-db:amd64 (2.1.28+dfsg1-9) ...\n",
      "Setting up libp11-kit0:amd64 (0.25.5-3) ...\n",
      "Setting up libunistring5:amd64 (1.3-2) ...\n",
      "Setting up libk5crypto3:amd64 (1.21.3-5) ...\n",
      "Setting up libsasl2-2:amd64 (2.1.28+dfsg1-9) ...\n",
      "Setting up libnghttp3-9:amd64 (1.8.0-1) ...\n",
      "Setting up perl-modules-5.40 (5.40.1-6) ...\n",
      "Setting up libtasn1-6:amd64 (4.20.0-2) ...\n",
      "Setting up git-man (1:2.47.3-0+deb13u1) ...\n",
      "Setting up libngtcp2-16:amd64 (1.11.0-1) ...\n",
      "Setting up libkrb5-3:amd64 (1.21.3-5) ...\n",
      "Setting up libssh2-1t64:amd64 (1.11.1-1) ...\n",
      "Setting up libldap2:amd64 (2.6.10+dfsg-1) ...\n",
      "Setting up libidn2-0:amd64 (2.3.8-2) ...\n",
      "Setting up libperl5.40:amd64 (5.40.1-6) ...\n",
      "Setting up perl (5.40.1-6) ...\n",
      "Setting up libgssapi-krb5-2:amd64 (1.21.3-5) ...\n",
      "Setting up libgnutls30t64:amd64 (3.8.9-3) ...\n",
      "Setting up libpsl5t64:amd64 (0.21.2-1.1+b1) ...\n",
      "Setting up liberror-perl (0.17030-1) ...\n",
      "Setting up librtmp1:amd64 (2.4+20151223.gitfa8646d.1-2+b5) ...\n",
      "Setting up libngtcp2-crypto-gnutls8:amd64 (1.11.0-1) ...\n",
      "Setting up libcurl3t64-gnutls:amd64 (8.14.1-2+deb13u2) ...\n",
      "Setting up git (1:2.47.3-0+deb13u1) ...\n",
      "Processing triggers for libc-bin (2.41-12) ...\n",
      "Removing intermediate container 65bd519c294d\n",
      " ---> a699d0a02d3f\n",
      "Step 5/10 : WORKDIR /app\n",
      " ---> Running in fd2f733bab3f\n",
      "Removing intermediate container fd2f733bab3f\n",
      " ---> e8dc5d61eb7d\n",
      "Step 6/10 : COPY requirements.txt .\n",
      " ---> fefc103b3bb7\n",
      "Step 7/10 : RUN pip install --no-cache-dir -r requirements.txt\n",
      " ---> Running in 8de6fdbf9edb\n",
      "Collecting fastapi\n",
      "  Downloading fastapi-0.122.0-py3-none-any.whl (110 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 110.7/110.7 kB 4.8 MB/s eta 0:00:00\n",
      "Collecting uvicorn[standard]\n",
      "  Downloading uvicorn-0.38.0-py3-none-any.whl (68 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 68.1/68.1 kB 40.8 MB/s eta 0:00:00\n",
      "Collecting torch\n",
      "  Downloading torch-2.9.1-cp310-cp310-manylinux_2_28_x86_64.whl (899.8 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 899.8/899.8 MB 209.6 MB/s eta 0:00:00\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.57.3-py3-none-any.whl (12.0 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 12.0/12.0 MB 211.5 MB/s eta 0:00:00\n",
      "Collecting pydantic\n",
      "  Downloading pydantic-2.12.5-py3-none-any.whl (463 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 463.6/463.6 kB 292.9 MB/s eta 0:00:00\n",
      "Collecting typing-extensions>=4.8.0\n",
      "  Downloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 44.6/44.6 kB 178.4 MB/s eta 0:00:00\n",
      "Collecting annotated-doc>=0.0.2\n",
      "  Downloading annotated_doc-0.0.4-py3-none-any.whl (5.3 kB)\n",
      "Collecting starlette<0.51.0,>=0.40.0\n",
      "  Downloading starlette-0.50.0-py3-none-any.whl (74 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 74.0/74.0 kB 177.5 MB/s eta 0:00:00\n",
      "Collecting click>=7.0\n",
      "  Downloading click-8.3.1-py3-none-any.whl (108 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 108.3/108.3 kB 228.3 MB/s eta 0:00:00\n",
      "Collecting h11>=0.8\n",
      "  Downloading h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Collecting watchfiles>=0.13\n",
      "  Downloading watchfiles-1.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (455 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 455.6/455.6 kB 258.2 MB/s eta 0:00:00\n",
      "Collecting httptools>=0.6.3\n",
      "  Downloading httptools-0.7.1-cp310-cp310-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (440 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 440.9/440.9 kB 233.0 MB/s eta 0:00:00\n",
      "Collecting pyyaml>=5.1\n",
      "  Downloading pyyaml-6.0.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (770 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 770.3/770.3 kB 277.6 MB/s eta 0:00:00\n",
      "Collecting python-dotenv>=0.13\n",
      "  Downloading python_dotenv-1.2.1-py3-none-any.whl (21 kB)\n",
      "Collecting websockets>=10.4\n",
      "  Downloading websockets-15.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (181 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 181.6/181.6 kB 264.5 MB/s eta 0:00:00\n",
      "Collecting uvloop>=0.15.1\n",
      "  Downloading uvloop-0.22.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (3.7 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.7/3.7 MB 248.1 MB/s eta 0:00:00\n",
      "Collecting nvidia-cublas-cu12==12.8.4.1\n",
      "  Downloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 594.3/594.3 MB 192.5 MB/s eta 0:00:00\n",
      "Collecting nvidia-cufile-cu12==1.13.1.3\n",
      "  Downloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 273.9 MB/s eta 0:00:00\n",
      "Collecting fsspec>=0.8.5\n",
      "  Downloading fsspec-2025.10.0-py3-none-any.whl (200 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 201.0/201.0 kB 231.2 MB/s eta 0:00:00\n",
      "Collecting sympy>=1.13.3\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.3/6.3 MB 209.8 MB/s eta 0:00:00\n",
      "Collecting nvidia-nvjitlink-cu12==12.8.93\n",
      "  Downloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 39.3/39.3 MB 210.6 MB/s eta 0:00:00\n",
      "Collecting nvidia-cusparselt-cu12==0.7.1\n",
      "  Downloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl (287.2 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 287.2/287.2 MB 214.0 MB/s eta 0:00:00\n",
      "Collecting nvidia-cudnn-cu12==9.10.2.21\n",
      "  Downloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl (706.8 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 706.8/706.8 MB 224.4 MB/s eta 0:00:00\n",
      "Collecting nvidia-cuda-runtime-cu12==12.8.90\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 954.8/954.8 kB 259.1 MB/s eta 0:00:00\n",
      "Collecting triton==3.5.1\n",
      "  Downloading triton-3.5.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (170.3 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 170.3/170.3 MB 223.1 MB/s eta 0:00:00\n",
      "Collecting jinja2\n",
      "  Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 134.9/134.9 kB 268.0 MB/s eta 0:00:00\n",
      "Collecting nvidia-nccl-cu12==2.27.5\n",
      "  Downloading nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.3 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 322.3/322.3 MB 220.2 MB/s eta 0:00:00\n",
      "Collecting networkx>=2.5.1\n",
      "  Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.7/1.7 MB 279.6 MB/s eta 0:00:00\n",
      "Collecting nvidia-cufft-cu12==11.3.3.83\n",
      "  Downloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 193.1/193.1 MB 210.4 MB/s eta 0:00:00\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.8.93\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 88.0/88.0 MB 212.5 MB/s eta 0:00:00\n",
      "Collecting nvidia-nvtx-cu12==12.8.90\n",
      "  Downloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 90.0/90.0 kB 226.4 MB/s eta 0:00:00\n",
      "Collecting filelock\n",
      "  Downloading filelock-3.20.0-py3-none-any.whl (16 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.9.90\n",
      "  Downloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 63.6/63.6 MB 217.1 MB/s eta 0:00:00\n",
      "Collecting nvidia-nvshmem-cu12==3.3.20\n",
      "  Downloading nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (124.7 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 124.7/124.7 MB 203.8 MB/s eta 0:00:00\n",
      "Collecting nvidia-cusolver-cu12==11.7.3.90\n",
      "  Downloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 267.5/267.5 MB 212.4 MB/s eta 0:00:00\n",
      "Collecting nvidia-cuda-cupti-cu12==12.8.90\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 10.2/10.2 MB 204.7 MB/s eta 0:00:00\n",
      "Collecting nvidia-cusparse-cu12==12.5.8.93\n",
      "  Downloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 288.2/288.2 MB 196.8 MB/s eta 0:00:00\n",
      "Collecting requests\n",
      "  Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 64.7/64.7 kB 159.9 MB/s eta 0:00:00\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0\n",
      "  Downloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.3/3.3 MB 242.3 MB/s eta 0:00:00\n",
      "Collecting huggingface-hub<1.0,>=0.34.0\n",
      "  Downloading huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 566.1/566.1 kB 255.5 MB/s eta 0:00:00\n",
      "Collecting tqdm>=4.27\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 78.5/78.5 kB 162.9 MB/s eta 0:00:00\n",
      "Collecting packaging>=20.0\n",
      "  Downloading packaging-25.0-py3-none-any.whl (66 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 66.5/66.5 kB 152.5 MB/s eta 0:00:00\n",
      "Collecting regex!=2019.12.17\n",
      "  Downloading regex-2025.11.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (791 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 791.7/791.7 kB 285.2 MB/s eta 0:00:00\n",
      "Collecting numpy>=1.17\n",
      "  Downloading numpy-2.2.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 16.8/16.8 MB 190.6 MB/s eta 0:00:00\n",
      "Collecting safetensors>=0.4.3\n",
      "  Downloading safetensors-0.7.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (507 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 507.2/507.2 kB 252.8 MB/s eta 0:00:00\n",
      "Collecting typing-inspection>=0.4.2\n",
      "  Downloading typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
      "Collecting annotated-types>=0.6.0\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Collecting pydantic-core==2.41.5\n",
      "  Downloading pydantic_core-2.41.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.1/2.1 MB 254.3 MB/s eta 0:00:00\n",
      "Collecting hf-xet<2.0.0,>=1.1.3\n",
      "  Downloading hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.3/3.3 MB 239.9 MB/s eta 0:00:00\n",
      "Collecting anyio<5,>=3.6.2\n",
      "  Downloading anyio-4.11.0-py3-none-any.whl (109 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 109.1/109.1 kB 234.0 MB/s eta 0:00:00\n",
      "Collecting mpmath<1.4,>=1.1.0\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 536.2/536.2 kB 216.2 MB/s eta 0:00:00\n",
      "Collecting MarkupSafe>=2.0\n",
      "  Downloading markupsafe-3.0.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (20 kB)\n",
      "Collecting idna<4,>=2.5\n",
      "  Downloading idna-3.11-py3-none-any.whl (71 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 71.0/71.0 kB 170.2 MB/s eta 0:00:00\n",
      "Collecting certifi>=2017.4.17\n",
      "  Downloading certifi-2025.11.12-py3-none-any.whl (159 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 159.4/159.4 kB 259.9 MB/s eta 0:00:00\n",
      "Collecting urllib3<3,>=1.21.1\n",
      "  Downloading urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 129.8/129.8 kB 232.6 MB/s eta 0:00:00\n",
      "Collecting charset_normalizer<4,>=2\n",
      "  Downloading charset_normalizer-3.4.4-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (153 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 153.6/153.6 kB 221.8 MB/s eta 0:00:00\n",
      "Collecting sniffio>=1.1\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Collecting exceptiongroup>=1.0.2\n",
      "  Downloading exceptiongroup-1.3.1-py3-none-any.whl (16 kB)\n",
      "Installing collected packages: nvidia-cusparselt-cu12, mpmath, websockets, uvloop, urllib3, typing-extensions, triton, tqdm, sympy, sniffio, safetensors, regex, pyyaml, python-dotenv, packaging, nvidia-nvtx-cu12, nvidia-nvshmem-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, MarkupSafe, idna, httptools, hf-xet, h11, fsspec, filelock, click, charset_normalizer, certifi, annotated-types, annotated-doc, uvicorn, typing-inspection, requests, pydantic-core, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, jinja2, exceptiongroup, pydantic, nvidia-cusolver-cu12, huggingface-hub, anyio, watchfiles, torch, tokenizers, starlette, transformers, fastapi\n",
      "Successfully installed MarkupSafe-3.0.3 annotated-doc-0.0.4 annotated-types-0.7.0 anyio-4.11.0 certifi-2025.11.12 charset_normalizer-3.4.4 click-8.3.1 exceptiongroup-1.3.1 fastapi-0.122.0 filelock-3.20.0 fsspec-2025.10.0 h11-0.16.0 hf-xet-1.2.0 httptools-0.7.1 huggingface-hub-0.36.0 idna-3.11 jinja2-3.1.6 mpmath-1.3.0 networkx-3.4.2 numpy-2.2.6 nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvrtc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cudnn-cu12-9.10.2.21 nvidia-cufft-cu12-11.3.3.83 nvidia-cufile-cu12-1.13.1.3 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-cusparselt-cu12-0.7.1 nvidia-nccl-cu12-2.27.5 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvshmem-cu12-3.3.20 nvidia-nvtx-cu12-12.8.90 packaging-25.0 pydantic-2.12.5 pydantic-core-2.41.5 python-dotenv-1.2.1 pyyaml-6.0.3 regex-2025.11.3 requests-2.32.5 safetensors-0.7.0 sniffio-1.3.1 starlette-0.50.0 sympy-1.14.0 tokenizers-0.22.1 torch-2.9.1 tqdm-4.67.1 transformers-4.57.3 triton-3.5.1 typing-extensions-4.15.0 typing-inspection-0.4.2 urllib3-2.5.0 uvicorn-0.38.0 uvloop-0.22.1 watchfiles-1.1.1 websockets-15.0.1\n",
      "\u001b[91mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\u001b[0m\u001b[91m\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.3\n",
      "[notice] To update, run: pip install --upgrade pip\n",
      "\u001b[0mRemoving intermediate container 8de6fdbf9edb\n",
      " ---> 222ea5338a35\n",
      "Step 8/10 : COPY main.py .\n",
      " ---> 106c43a20559\n",
      "Step 9/10 : EXPOSE 8080\n",
      " ---> Running in 19b535c9e6a9\n",
      "Removing intermediate container 19b535c9e6a9\n",
      " ---> c79c332f04b0\n",
      "Step 10/10 : CMD [\"uvicorn\", \"main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8080\"]\n",
      " ---> Running in 9bdf45520125\n",
      "Removing intermediate container 9bdf45520125\n",
      " ---> d9f6bfa845f1\n",
      "Successfully built d9f6bfa845f1\n",
      "Successfully tagged us-central1-docker.pkg.dev/vast-collective-478617-j1/vertex-mlops-repo/imdb-sentiment-bert:v1\n",
      "PUSH\n",
      "Pushing us-central1-docker.pkg.dev/vast-collective-478617-j1/vertex-mlops-repo/imdb-sentiment-bert:v1\n",
      "The push refers to repository [us-central1-docker.pkg.dev/vast-collective-478617-j1/vertex-mlops-repo/imdb-sentiment-bert]\n",
      "15a9b1b80fad: Preparing\n",
      "15aea82d7942: Preparing\n",
      "930b230b622b: Preparing\n",
      "523b073e291e: Preparing\n",
      "c3f44cba36d3: Preparing\n",
      "548ba1e7e829: Preparing\n",
      "a8045a14b5f4: Preparing\n",
      "cb4ecf39d967: Preparing\n",
      "70a290c5e58b: Preparing\n",
      "15a9b1b80fad: Pushed\n",
      "523b073e291e: Pushed\n",
      "930b230b622b: Pushed\n",
      "548ba1e7e829: Pushed\n",
      "cb4ecf39d967: Pushed\n",
      "a8045a14b5f4: Pushed\n",
      "c3f44cba36d3: Pushed\n",
      "70a290c5e58b: Pushed\n",
      "15aea82d7942: Pushed\n",
      "v1: digest: sha256:c5080a9a3593ccb352a1b2f2c7ff09ffcfd2308f31d6980a34af6de8f9fe531e size: 2206\n",
      "DONE\n",
      "--------------------------------------------------------------------------------\n",
      "ID                                    CREATE_TIME                DURATION  SOURCE                                                                                                   IMAGES                                                                                         STATUS\n",
      "627a9a13-a235-45a8-a346-4ca77253d26e  2025-11-27T10:10:17+00:00  7M50S     gs://vast-collective-478617-j1_cloudbuild/source/1764238217.206755-305469b3485b4337b2e6485866cc65ce.tgz  us-central1-docker.pkg.dev/vast-collective-478617-j1/vertex-mlops-repo/imdb-sentiment-bert:v1  SUCCESS\n"
     ]
    }
   ],
   "source": [
    "!gcloud builds submit --tag {IMAGE_URI} .\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78616584-942e-45c6-8c2b-e85dcf89e686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Upload the model to Vertex AI\n",
    "\n",
    "# Now we register the container image as a Vertex AI Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "82b47d29-7778-4c6c-a52b-a962bef1dd38",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T10:25:11.710262Z",
     "iopub.status.busy": "2025-11-27T10:25:11.709789Z",
     "iopub.status.idle": "2025-11-27T10:29:09.157659Z",
     "shell.execute_reply": "2025-11-27T10:29:09.156246Z",
     "shell.execute_reply.started": "2025-11-27T10:25:11.710226Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Model\n",
      "Create Model backing LRO: projects/60487384516/locations/us-central1/models/3642786476426526720/operations/2142734084185522176\n",
      "Model created. Resource name: projects/60487384516/locations/us-central1/models/3642786476426526720@1\n",
      "To use this Model in another session:\n",
      "model = aiplatform.Model('projects/60487384516/locations/us-central1/models/3642786476426526720@1')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'projects/60487384516/locations/us-central1/models/3642786476426526720'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from google.cloud import aiplatform\n",
    "\n",
    "aiplatform.init(project=PROJECT_ID, location=LOCATION)\n",
    "\n",
    "model = aiplatform.Model.upload(\n",
    "    display_name=MODEL_DISPLAY_NAME,\n",
    "    serving_container_image_uri=IMAGE_URI,\n",
    "    serving_container_predict_route=\"/predict\",\n",
    "    serving_container_health_route=\"/ping\",\n",
    ")\n",
    "\n",
    "model.resource_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832a449f-3964-4da0-bc86-655b6c7dcfbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3265681-029f-49b7-9f04-e7ff571c5625",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Create an Endpoint and deploy the model\n",
    "\n",
    "# You can either create a new endpoint or reuse an existing one. Here we create a fresh endpoint and deploy this model to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "acb48479-3015-4e82-b8a4-21336bee24dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T10:34:53.722013Z",
     "iopub.status.busy": "2025-11-27T10:34:53.720734Z",
     "iopub.status.idle": "2025-11-27T10:34:55.823597Z",
     "shell.execute_reply": "2025-11-27T10:34:55.822163Z",
     "shell.execute_reply.started": "2025-11-27T10:34:53.721949Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Endpoint\n",
      "Create Endpoint backing LRO: projects/60487384516/locations/us-central1/endpoints/8963103340909035520/operations/5757435735103766528\n",
      "Endpoint created. Resource name: projects/60487384516/locations/us-central1/endpoints/8963103340909035520\n",
      "To use this Endpoint in another session:\n",
      "endpoint = aiplatform.Endpoint('projects/60487384516/locations/us-central1/endpoints/8963103340909035520')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'projects/60487384516/locations/us-central1/endpoints/8963103340909035520'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint = aiplatform.Endpoint.create(display_name=ENDPOINT_DISPLAY_NAME)\n",
    "endpoint.resource_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fac5745a-c184-4b42-a6d4-45259451392b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T10:36:44.890436Z",
     "iopub.status.busy": "2025-11-27T10:36:44.889990Z",
     "iopub.status.idle": "2025-11-27T11:16:04.344226Z",
     "shell.execute_reply": "2025-11-27T11:16:04.342651Z",
     "shell.execute_reply.started": "2025-11-27T10:36:44.890401Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploying model to Endpoint : projects/60487384516/locations/us-central1/endpoints/8963103340909035520\n",
      "Deploy Endpoint model backing LRO: projects/60487384516/locations/us-central1/endpoints/8963103340909035520/operations/1479860514031927296\n",
      "Endpoint model deployed. Resource name: projects/60487384516/locations/us-central1/endpoints/8963103340909035520\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'projects/60487384516/locations/us-central1/endpoints/8963103340909035520'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deploy_op = model.deploy(\n",
    "    endpoint=endpoint,\n",
    "    machine_type=\"n1-standard-2\",  # or e2-standard-2/4 etc\n",
    "    min_replica_count=1,\n",
    "    max_replica_count=1,\n",
    "    traffic_percentage=100,\n",
    "    sync=True,\n",
    ")\n",
    "\n",
    "endpoint.resource_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a8d39d-398e-4dbe-9624-9e2ba28e713b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30e5da1-85f5-45ac-8433-c9d34a03a4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Test online predictions from the notebook\n",
    "\n",
    "# Now call the deployed endpoint using the Vertex AI Python SDK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e7562267-a5ed-479f-89b2-bf45b41f3bc0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T11:29:47.974912Z",
     "iopub.status.busy": "2025-11-27T11:29:47.974502Z",
     "iopub.status.idle": "2025-11-27T11:29:50.202841Z",
     "shell.execute_reply": "2025-11-27T11:29:50.201643Z",
     "shell.execute_reply.started": "2025-11-27T11:29:47.974880Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(predictions=[{'confidence': 99.76, 'sentiment': 'Positive', 'text': 'This movie was absolutely fantastic!'}, {'confidence': 99.75, 'sentiment': 'Negative', 'text': 'I really disliked this movie, it was terrible.'}], deployed_model_id='770519057047748608', metadata=None, model_version_id='1', model_resource_name='projects/60487384516/locations/us-central1/models/3642786476426526720', explanations=None)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from google.cloud import aiplatform\n",
    "\n",
    "aiplatform.init(project=PROJECT_ID, location=LOCATION)\n",
    "\n",
    "endpoint = aiplatform.Endpoint(endpoint_name=endpoint.resource_name)\n",
    "\n",
    "test_instances = [\n",
    "    {\"text\": \"This movie was absolutely fantastic!\"},\n",
    "    {\"text\": \"I really disliked this movie, it was terrible.\"},\n",
    "]\n",
    "\n",
    "response = endpoint.predict(instances=test_instances)\n",
    "response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1bd4b6a7-d8bc-429f-a971-7d93eb1201e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T11:30:43.708374Z",
     "iopub.status.busy": "2025-11-27T11:30:43.707959Z",
     "iopub.status.idle": "2025-11-27T11:30:43.714054Z",
     "shell.execute_reply": "2025-11-27T11:30:43.712555Z",
     "shell.execute_reply.started": "2025-11-27T11:30:43.708325Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'confidence': 99.76, 'sentiment': 'Positive', 'text': 'This movie was absolutely fantastic!'}, {'confidence': 99.75, 'sentiment': 'Negative', 'text': 'I really disliked this movie, it was terrible.'}]\n"
     ]
    }
   ],
   "source": [
    "print(response.predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3670095-ed08-429d-b61d-0ddd544be625",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2a15d49c-4f6b-4c23-a0e8-184dc5a750f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T11:31:27.456900Z",
     "iopub.status.busy": "2025-11-27T11:31:27.456455Z",
     "iopub.status.idle": "2025-11-27T11:31:27.463409Z",
     "shell.execute_reply": "2025-11-27T11:31:27.461917Z",
     "shell.execute_reply.started": "2025-11-27T11:31:27.456862Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: This movie was absolutely fantastic!\n",
      "Sentiment: Positive, Confidence: 99.76%\n",
      "\n",
      "Text: I really disliked this movie, it was terrible.\n",
      "Sentiment: Negative, Confidence: 99.75%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for pred in response.predictions:\n",
    "    print(\n",
    "        f\"Text: {pred['text']}\\n\"\n",
    "        f\"Sentiment: {pred['sentiment']}, \"\n",
    "        f\"Confidence: {pred['confidence']}%\\n\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9cb39fe8-7d62-418a-b648-5f1535964633",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T11:32:35.904974Z",
     "iopub.status.busy": "2025-11-27T11:32:35.904505Z",
     "iopub.status.idle": "2025-11-27T11:32:35.911376Z",
     "shell.execute_reply": "2025-11-27T11:32:35.909563Z",
     "shell.execute_reply.started": "2025-11-27T11:32:35.904928Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Optional Clean up resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bf2f62-c655-418d-95d8-639f8d289d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. (Optional) Clean up resources\n",
    "\n",
    "# Run these if you want to delete the endpoint and model when you are done to avoid charges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b950d9-6811-4e26-a333-1d3d55e5155d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Undeploy and delete endpoint\n",
    "# endpoint.undeploy_all()\n",
    "# endpoint.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e8654f-ed62-42e8-89e2-048921c8bfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Delete model\n",
    "# model.delete()"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m136",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m136"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
